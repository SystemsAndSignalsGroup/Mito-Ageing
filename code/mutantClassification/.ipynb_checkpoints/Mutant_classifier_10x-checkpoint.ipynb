{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to classify mutants output by the variant calling pipeline for any scenario where the sample_id is of the form GSM_BARCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Metadata/parkinsons_metadata.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a0d8899dd432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Metadata/parkinsons_metadata.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SC/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     ) as handles:\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/SC/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Metadata/parkinsons_metadata.pkl'"
     ]
    }
   ],
   "source": [
    "md = pd.read_pickle(\"./Metadata/parkinsons_metadata.pkl\")\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_dict = dict(zip(md.GSM_id, md.donor_id)) # Links GSM to a useful unique donor identifier from the metadata\n",
    "gsm_dict = dict(zip(md.SRR_id, md.GSM_id)) # Links SRR to GSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges all the depth files into a single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_files = glob.glob(f\"./Data/variant/*/*depth.csv\") # List of all donor files from all GSMs\n",
    "depth_frames = (pd.read_csv(f) for f in depth_files)\n",
    "depth_all  = pd.concat(depth_frames, ignore_index=False, sort = False)\n",
    "print('Done!')\n",
    "depth_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below splits barcode from GSM and then maps it to donor_id. If the mapping is not 1-1 then an additional map must be made to keep this correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dict = dict(zip(depth_all.sample_id,depth_all.bases_passed))\n",
    "\n",
    "depth_all['GSM'] = depth_all.sample_id.str.split('_',n = 1, expand = True)[0]\n",
    "depth_all['barcode'] = depth_all.sample_id.str.split('_',n = 1, expand = True)[1]\n",
    "\n",
    "depth_all['donor_id'] = depth_all['GSM'].map(donor_dict)\n",
    "\n",
    "depth_all.to_pickle(f'./Data/depthAll.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a threshold on the bases passed based off the plot generated below - good quality cells should have a roughly log-normal distribution on the number of bases passed so try to cut off any which skew this distribution. Anything with fewer than 100 bases passing should be treated cautiously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_arr = [0]\n",
    "bin_arr.extend(np.logspace(np.log10(1),np.log10(100000), 50))\n",
    "plt.hist((depth_all['bases_passed']),bins=bin_arr)\n",
    "plt.xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 300\n",
    "passed_samples = depth_all[depth_all['bases_passed']>threshold]\n",
    "\n",
    "# This is the file needed to re-filter the expression matrix\n",
    "np.savetxt('mitochondrialFilteredBarcodes.txt', passed_samples.drop_duplicates['sample_id'], fmt=\"%s\")\n",
    "\n",
    "variant_files = []\n",
    "coverage_files = []\n",
    "variant_files.extend(list('./Data/variant/' + passed_samples['GSM'] + '/' +passed_samples['sample_id'] + '_variants.csv'))\n",
    "coverage_files.extend(list('./Data/variant/'  + passed_samples['GSM'] + '/' + passed_samples['sample_id'] + '_coverage.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges all the coverage files passing quality control into a single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage=pd.DataFrame(index=list(range(0,16569))) # Edit this to genome length of species\n",
    "\n",
    "# The below creates a new column for every coverage file by mapping the index to the coverage of that cell\n",
    "for f in coverage_files:\n",
    "    huh = pd.read_pickle(f)\n",
    "    coverage[f.split('/')[-1][:-13]] = coverage.index.map(huh)\n",
    "    \n",
    "# Creates a multi-index column for easy reference to donor and barcode\n",
    "cell_ids = pd.DataFrame(coverage.columns).T\n",
    "coverage.columns = pd.MultiIndex.from_frame(pd.DataFrame(cell_ids.iloc[0].str.split('_',n=0, expand=True)).rename(columns={0:'donor_id',1:'sample_id'}))\n",
    "\n",
    "coverage=coverage.sort_values(by=['donor_id','sample_id'],  axis=1)\n",
    "\n",
    "coverage.to_pickle('./Data/coverage.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to whatever depth threshold you used for variant calling (default 200)\n",
    "coverage_lim=200\n",
    "\n",
    "# Creates a dictionary mapping every position to the number of cells \n",
    "# from a donor which covered that position at sufficient depth for variant calling\n",
    "cell_base={}\n",
    "for GSM in md.GSM_id.unique().astype(str):\n",
    "    \n",
    "    split=coverage.xs(GSM, level='donor_id', axis=1).fillna(0) > coverage_lim\n",
    "    \n",
    "    cell_base.update({GSM+'_'+str(k) : v for k, v in dict(split.sum(axis=1)).items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_frames = (pd.read_csv(f) for f in variant_files)\n",
    "d_donor_all  = pd.concat(variant_frames, ignore_index=False, sort = False)\n",
    "print('Done!')\n",
    "d_donor_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits the GSM from the barcode and then maps it to the donor id\n",
    "# Only works for 1-1 mapping of donor->GSM (is fine for multiple GSMs per donor)\n",
    "\n",
    "d_donor_all['GSM'] = d_donor_all[\"sample_id\"].str.split('_',n = 1, expand = True)[0]\n",
    "d_donor_all['donor_id'] = d_donor_all['GSM'].map(donor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps sample id to how many bases passed the filter\n",
    "\n",
    "base_dict = dict(zip(depth_all.sample_id,depth_all.bases_passed))\n",
    "d_donor_all['bases_passed'] = d_donor_all.sample_id.map(base_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_donor_all['MUT'] = d_donor_all['REF']+d_donor_all['POS'].apply(str)+d_donor_all['ALT']\n",
    "d_donor_all['donor_mut'] = d_donor_all['GSM'].astype(str)+d_donor_all['MUT']\n",
    "d_donor_all['donor_POS'] =  d_donor_all['GSM'].astype(str)+'_'+d_donor_all['POS'].astype(str)\n",
    "d_donor_all['cells_possible'] = d_donor_all.donor_POS.map(cell_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following splits up mutations from each donor and labels the average heteroplasmy they appear at (given that they do appear), the standard deviation of heteroplasmy and the proportion of cells from a donor they appear in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_stats = pd.DataFrame()\n",
    "\n",
    "mutant_group = d_donor_all[['donor_id','donor_mut','HF','MUT','sample_id','cells_possible']].groupby(['donor_id','MUT','donor_mut'])\n",
    "mutant_stats['average'] = mutant_group['HF','donor_mut'].mean()['HF']\n",
    "mutant_stats['standardD'] = mutant_group['HF','donor_mut'].std()['HF']\n",
    "mutant_stats['mutant_sequenced_prop'] = (mutant_group['sample_id'].count()/mutant_group['cells_possible'].mean())\n",
    "\n",
    "mean_het = dict(zip(mutant_stats.index.get_level_values(level='donor_mut'),mutant_stats.average))\n",
    "cell_prop = dict(zip(mutant_stats.index.get_level_values(level='donor_mut'),mutant_stats.mutant_sequenced_prop))\n",
    "std_dict = dict(zip(mutant_stats.index.get_level_values(level='donor_mut'),mutant_stats.standardD))\n",
    "\n",
    "d_donor_all['mutant_sequenced_prop']=d_donor_all['donor_mut'].map(cell_prop)\n",
    "d_donor_all['mean_HF']=d_donor_all['donor_mut'].map(mean_het)\n",
    "d_donor_all['mutant_stds']=d_donor_all['donor_mut'].map(std_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of GSM to number of cells\n",
    "donor_cell_dict={}\n",
    "for GSM in d_donor_all.GSM.unique():\n",
    "    donor_cell_dict[GSM] = len(passed_samples[passed_samples.GSM == GSM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_donor_all['base_cell_prop'] = d_donor_all.cells_possible/d_donor_all.GSM.map(donor_cell_dict) # Proportion of all donor cells the base is covered by\n",
    "d_donor_all['mutant_donor_prop'] = d_donor_all.base_cell_prop*d_donor_all.mutant_sequenced_prop # Proportion of all donor cells mutant is found in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This identifies any mutations which are not haplotype or cryptic, and appear in all donors from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all mutations which are not haplotype (mean_HF>0.95) by donor\n",
    "donor_no_haps={}\n",
    "for donor in d_donor_all.donor_id.unique():\n",
    "    donor_no_haps[donor] = mutant_stats.loc[donor][mutant_stats.loc[donor]['average']<0.95]\n",
    "\n",
    "# Creates a list of all mutations found in each donor and then counts how many times they appear in the list\n",
    "mutations=[]\n",
    "for donor in d_donor_all.donor_id.unique():\n",
    "    mutantions.extend(donor_no_haps[donor].index.get_level_values(level='MUT'))\n",
    "uni = Counter(mutations)\n",
    "\n",
    "# Creates list of all mutations which appear in more than three donors\n",
    "common_mut=[]\n",
    "for key in uni: \n",
    "    if uni[key] >3:\n",
    "        common_mut.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates column ['Mutant_type'] to identify every mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the mutations common across all donors\n",
    "common = d_donor_all[d_donor_all['MUT'].isin(common_mut)]\n",
    "common['type'] = 'Common mutation'\n",
    "common_dict=dict(zip(common.donor_mut,common.type))\n",
    "\n",
    "# Find all the cryptic mutations\n",
    "singletons = d_donor_all.drop_duplicates(subset = ['donor_mut'], keep = False)\n",
    "singletons['single']='Cryptic'\n",
    "single_dict = dict(zip(singletons.donor_mut,singletons.single))\n",
    "\n",
    "# Find Haplotype Mutations\n",
    "others = d_donor_all[((~d_donor_all['donor_mut'].isin(singletons['donor_mut']))&(~d_donor_all['donor_mut'].isin(list(common_dict.keys()))))]\n",
    "fully_sequenced = others[((others.mutant_sequenced_prop> 0.95))]\n",
    "fully_sequenced['full'] = 'Full Sequenced'\n",
    "fully_sequenced_dict = dict(zip(fully_sequenced.donor_mut,fully_sequenced.full))\n",
    "\n",
    "# Find Inherited Mutations\n",
    "partial_sequenced = others[~others['donor_mut'].isin(fully_sequenced['donor_mut'])]\n",
    "partial_sequenced['hap'] = 'Part Sequenced'\n",
    "part_dict = dict(zip(partial_sequenced.donor_mut,partial_sequenced.hap))\n",
    "\n",
    "# Label all the mutation types in the full frame\n",
    "mut_type_dict = {**common_dict , **single_dict, **fully_sequenced_dict, **part_dict}\n",
    "d_donor_all['mutant_type'] = d_donor_all['donor_mut'].map(mut_type_dict)\n",
    "\n",
    "d_donor_all = d_donor_all.drop(columns=['donor_mut','donor_POS']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is only applicable to human data - it queries every mutation against a database which can predict how pathological it is going it be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pickle.load(open('mutPred_prob.pkl', 'rb'))\n",
    "classes = pickle.load(open('mutPred_pred.pkl', 'rb'))\n",
    "aachange = pickle.load(open('aachange.pkl', 'rb'))\n",
    "haplomap = pickle.load(open('haplomap.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_donor_all['MutPred_Probability'] = d_donor_all['MUT'].map(scores)\n",
    "d_donor_all['MutPred_Prediction'] = d_donor_all['MUT'].map(classes)\n",
    "d_donor_all['AAchange'] = d_donor_all['MUT'].map(aachange)\n",
    "d_donor_all['haplotypes'] = d_donor_all['MUT'].map(haplomap)\n",
    "d_donor_all = d_donor_all.drop(columns=['MUT']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This labels protein coding mutations depending on the effect they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, aa in enumerate(d_donor_all['AAchange']):\n",
    "    if pd.isna(d_donor_all.loc[i]['AAchange']):\n",
    "        continue\n",
    "    elif d_donor_all.loc[i]['AAchange'][0] == '.':\n",
    "        continue\n",
    "    elif d_donor_all.loc[i]['AAchange'][0] == d_donor_all.loc[i]['AAchange'][-1]:\n",
    "        d_donor_all.loc[i,'MutPred_Probability'] = 0\n",
    "        d_donor_all.loc[i,'MutPred_Prediction'] = 'Synonymous'\n",
    "    elif ((d_donor_all.loc[i]['AAchange'][0] == 'X') or (d_donor_all.loc[i]['AAchange'][-1] == 'X')):\n",
    "        d_donor_all.loc[i,'MutPred_Prediction'] = 'Non-Synonymous Stop Substitution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_donor_all.to_pickle('./Data/variants.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will now create the fully filtered expression matrix with both expression and mitochondrial quality control done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip this if your expression matrix is still loaded\n",
    "\n",
    "GSM_list = pd.read_csv('gsm.txt',header=None)\n",
    "filenames = []\n",
    "for i in GSM_list:\n",
    "    filenames.append(f'./Data/Expression/{i}/raw')\n",
    "\n",
    "# Reads in expression matrices for every GSM in your dataset    \n",
    "adatas = [sc.read_10x_mtx(filename) for filename in filenames]\n",
    "\n",
    "# To account for the possibility of barcodes appearing in multiple GSMs we have to append the GSM to the front of the barcode for all GSMs\n",
    "for i , GSM in enumerate(GSM_list):\n",
    "    adatas[i].obs.index = f'{GSM}_' + adatas[i].obs.index\n",
    "    \n",
    "# Creates one giant expression matrix from the whole experiment to do quality control on\n",
    "adata = adatas[0].concatenate(adatas[1:],index_unique=None)\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodess = pd.read_csv('mitochondrialFilteredBarcodes.txt',header=None) # This file should have been created by Mutant_Classifier_10x.ipynb\n",
    "adata = adata[bars[0]]\n",
    "sc.write('./FilteredExpression.h5ad',adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
